## Trusted connection paths through forums created in a given timeframe

That wordy title thar is the name for the [Linked Data Benchmark Council](http://ldbcouncil.org)'s [Business Intelligence Query 25](https://ldbc.github.io/ldbc_snb_docs_snapshot/bi-read-25.pdf). This query is going to be the subject of a few posts, as we attempt to implement what seems to be a pretty sophisticated query.

Rather than writting a massive missive about how you write such a query in one of several frameworks, I'm going to spill things out slowly. This is mainly to give people time to ponder the problem, and think about which parts are challenging and why. It is also to give me time to finish my implementation, which as it turns out doesn't just write itself.

* Breaking down the problem.
* Finding shortest paths in graphs.
* Scoring interactions of people.
* Filtering by dates.
* Reconstructing paths.
* A declarative implementation.

### Breaking down the problem

To start with, let's talk through [the problem](https://ldbc.github.io/ldbc_snb_docs_snapshot/bi-read-25.pdf).

If you plan to follow along, I strongly recommend clicking that link up there and reading a bit. It is a one pager which describes the query both in English prose and using a graphical query language. Although we'll introduce the language and components of the problem, I'll be writing as if you have access to the link above and can use it to resolve ambiguities.

Go read it!

#### The problem, briefly

Our task is to take as input pairs of "people", each represented by integer identifiers, and then find and *score* the shortest paths between them in a directed graph. The score for a path is determined by scoring each link based on the number and type of interactions between its endpoints, and then accumulating the scores of each link in the path. There is the additional complication that we should only accumulate interactions whose root event (these interactions are forum posts) has a date that lies in a specified interval.

The problem calls out a few interesting challenges, at least to my mind:

1.  **Finding shortest paths in graphs** is surprisingly harder than computing the distance between two nodes, which is surprisingly harder than computing the distance from one node to all other nodes in the graph, which is the only thing scalable graph processors bother to do with paths in graphs.

    We will need to be clever and careful here, to efficiently report the shortest paths in graphs between pairs of query nodes. For example, presumably you've noticed that "paths" is plural and not singular.

2.  **Link scoring** is potentially expensive, and not something we want to do for all interactions, but rather just those interactions that pique our interest.

3.  **Link filtering** is even more expensive, as it involves chasing down the root of a chain of interactions. There will be iteration.

4.  **Path scoring** at the very least involves data types that are vectors. Ideally we could have left the shortest path data as a DAG, but the query asks us to expand it out into the potentially (it won't be) exponentially many shortest paths and their scores.

And obviously because this is the blog you think it is, all of this should be scalable, interactive, and incrementally maintained as the data change.

It will be. Don't worry. ;)

#### The data and query inputs, and the output.

The query inputs are perhaps the simplest, so let's start there. Each instance of the query has four parameters (all in the linked pdf; go read it again!):

    person1Id:  usize,
    person2Id:  usize,
    startDate:  Date,
    endDate:    Date,

The data inputs come in three flavors (in my mind).

    knows:      (usize, usize),         // e.g. (person1, person2)
    posts:      (usize, usize, usize),  // e.g. (id, author, forum)
    comments:   (usize, usize, usize),  // e.g. (id, author, parent)
    forum:      (usize, Date),          // e.g. (id, creation_date)

This isn't exactly how LDBC represents things, but we'll deal with that when we get there.

The required output is, for each query quadruple a list of tuples with fields

    path:       Vec<usize>,
    score:      f64,

We are going to change the score to be a `usize` because we like doing math with correct answers, which in this case is all fine (we can double the requested scores and get integral non-negative scores).

#### Breaking apart the parts of the query.

I've written a fair bit of the query so far, and it comes in parts. They roughly track the challenges above, but I thought I'd start by sketching the structure without yet developing the details.

First, for reasons of sanity we are going to want to pretend to impose some type structure on all of these identifiers.

```rust
type Node = usize;  // identifies a person.
type Text = usize;  // identifies a post or comment.
type Forum = usize; // identifies a forum.
type Edge = (Node, Node);
```

These are just type aliases, and won't actually keep us from comparing people identifiers and forum identifiers, but it will at least let us be more clear about our intent. We could certainly create actual new types wrapping these identifiers, at the cost of a fair bit of boilerplate. I'm up for that, but once I understand that we have the right structure in place.

The skeleton I'm currently working with starts like so:

```rust
fn main() {

    // define a new computational scope, in which to run BFS
    timely::execute_from_args(std::env::args(), move |worker| {

        // Create a dataflow for BI Q25, returning handles to inputs.
        let (mut query, mut knows, mut posts, mut comms, mut forum) =
        worker.dataflow(|scope| {

            // Create various input handles and collections.
            let (query_input, query) = scope.new_collection();
            let (knows_input, knows) = scope.new_collection();
            let (posts_input, posts) = scope.new_collection();
            let (comms_input, comms) = scope.new_collection();
            let (forum_input, forum) = scope.new_collection();

            // 1. Determine edges in shortest paths, for each query.
            let goals = query.map(|(src,dst,_,_)| (src,dst));
            let mut shortest_edges: Collection<_,((Node, Node), Edge)> =
                = shortest_paths(&knows, &goals);

            // 2. Score each edge, broken down by the root post.
            let mut edge_scores: Collection<_, (Edge, Text)>
                = score_edges(&shortest_edges, &posts, &comms);

            // 3. Merge queries and scores, filter by start and end dates.
            let filtered_edges: Collection<_, ((Node, Node), (Edge, usize))>
                = unimplemented!();

            // 4. Reconstruct paths and scores.
            let scored_paths: Collection<_, ((Node, Node), (Vec<Node>, usize))>
                = unimplemented!();

            // 5. Announce massive success!
            scored_paths.inspect(|x| println!("WOW:\t{:?}", x));
```

As you can see, we are doing little more than creating a new dataflow graph, announcing some inputs we plan to use (one for each stated input, as well as an input for the queries themselves), and pretending to do the computation through some methods that may or may not yet exist (certainly not yet discussed).

I've clearly not written everything yet. I haven't even gotten around to figuring out the signature for the third and fourth steps yet! I kinda nailed step five though, I hope we agree.

#### Next steps

We have a few steps laid out ahead of us.

1.  We need to write the `shortest_paths` method. This method will need to go from a collection of goals `(source, target)` and produce `((source, target), edge)` for each `edge` on a shortest path from `source` to `target`. At least, that is what it *will* do.

    This method is going to be a bit of a beast. It is about 100 lines long, which is *enormous* for a differential dataflow method. I think it mostly makes sense though, at least taken in small parts at a time.

2.  We need to write the `score_edges` method. This method will need to check out various posts and comments and look for links among them that correspond to pairs of authors we saw in edges just above.

    This isn't so bad. It's much shorter at the moment, but it doesn't compile yet so .. right.

3.  We need to do the other steps too. Three and four. I think these are easier, but I'm writing this well before I've gotten to even thinking about that. Really, writing this is the first time I've thought about it, so there might be some fairly public failure here. That should be fun!

### Finding shortest paths in graphs

### Scoring interactions of people

### Filtering by dates

### Reconstructing paths

### A declarative implementation