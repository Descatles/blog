
## Programming with time

In this post we'll look at how to speed up (differential) dataflow computations by manipulating time. If you were looking around for a super-power to pick up, this might be the one.

Dataflow computations describe several independent bits of computation, and how each of these bits of computation should react to the arrival of new data. Unlike imperative computations, dataflow computations typically do *NOT* express any thoughts about which work should happen first, second, or last. In some interesting cases, this ambivalence can lead to sketchy performance.

Unlike vanilla dataflow systems, *timely* dataflow systems allow the programmatic manipulation of the timestamps associated with records. This allows programs to introduce sequential execution into their computation, a la carte.

### An exhausting example

Let's take the example of single-source shortest paths: we have as input a directed graph whose edges have weights (let's say strictly positive weight). For a query node, we want to produce all other nodes reachable along a directed path from the query node, and for each of these other nodes we must report the *least* path length: the sum of weights along the path.

For example, here is a picture of a directed graph with some edge weights on it:

**PICTURE**

Let's talk through how we might compute the shortest paths from a supplied single source.

There is a classic algorithm that starts from the source node, at distance zero, and then repeatedly improves the set of shortest distances by considering single steps along edges. Once we reach a point where no further improvements can be made, we have reached the correct answer!

We can write this as a differential dataflow computation, following the algorithmic sketch up above, and using differential dataflow's `iterate` method. In particular, we will iteratively set a collection `dists` to the result of joining `dists` with `edges`, adding whatever weight is on the edge, merging in initial distances, and retaining the minimum distance for each node.

It looks like this:

```rust
// Set up some aliases.
type Dist = u32;
type Node = u32;
type Edge = (Node, (Node, Dist));

// Returns pairs (n, s) indicating node n can be reached from a root in s steps.
fn sssp<G: Scope>(
    edges: &Collection<G, Edge>,    // Collection of edges.
    roots: &Collection<G, Node>,    // Initial sources.
) -> Collection<G, (Node, u32)>
where G::Timestamp: Lattice+Ord {

    // Initialize roots as reaching themselves at distance 0
    let nodes = roots.map(|x| (x, 0));

    // Repeatedly update minimal distances each node can be reached from each root
    nodes.iterate(|dists| {

        // Explicitly bring into scope ...
        let edges = edges.enter(&dists.scope());
        let nodes = nodes.enter(&dists.scope());

        // New `dists` set to:
        dists.join(&edges)
             .map(|(k,l,(d,w))| (d,l+w))
             .concat(&nodes)
             .reduce(|_, s, t| t.push((*s[0].0, 1)))
     })
}
```

That might be a bit of an eyeful to look at all at once, so take your time. We will return to parts of it as we go along.

Let's see how a computation like this runs!

We are going to go pretty simple in this post: we'll use random graphs on specified numbers of nodes and edges, and with edge weights drawn uniformly between specified minimum and maximum values. Our computation will first load up and run `sssp` on the input graph, and then perform a sequence of 1,000 random updates to the graph; we are interested in the times neede to perform both of these.

For example, let's take the easiest case of unit weights, which corresponds to the popular "breadth first search" problem:

|nodes|edges|minimum|maximum|compute|update|
|----:|----:|------:|------:|------:|-----:|
|1M   |  10M|      1|      1|  7.35s| 7.61s|

Nice! Maybe... Who even knows these days. Seven seconds might be a lot of time, but we can do a sequence of 1,000 updates in under 300 milliseconds, meaning each takes under a millisecond itself. That is great!

Now, we are here because there is something interesting that is going to happen. Let's see what happens as we vary .. the maximum weight setting. How suspicious...

|nodes|edges|minimum|maximum|compute|update|
|----:|----:|------:|------:|------:|-----:|
|1M   |  10M|      1|      1|  7.35s| 7.61s|
|1M   |  10M|      1|      2| 13.38s|13.85s|
|1M   |  10M|      1|      3| 18.04s|18.87s|
|1M   |  10M|      1|      4| 20.74s|21.61s|
|1M   |  10M|      1|      5| 27.61s|28.73s|

Things for sure got worse. Let's crank things up even further, by orders of magnitude variation.

|nodes|edges|minimum|maximum|compute| update|
|----:|----:|------:|------:|------:|------:|
|1M   |  10M|      1|      1|  7.35s|  7.61s|
|1M   |  10M|      1|     10| 41.44s| 44.06s|
|1M   |  10M|      1|    100| 82.21s| 87.58s|
|1M   |  10M|      1|   1000|100.75s|106.96s|

Our initial running time has increased by 13x, and the incremental update times have increased 20x from 300ms to 6 seconds.

Something has gone horribly wrong with SSSP as the variation in weights increases.

To help with our performance debugging, and because I know where this is going, let's do the same experiment where we add 1,000 to all weights. These weights have the same *absolute* range as the experiment above.

|nodes|edges|minimum|maximum|compute| update|
|----:|----:|------:|------:|------:|------:|
|1M   |  10M|   1000|   1000|  7.36s|  7.60s|
|1M   |  10M|   1000|   1010|  9.90s| 10.20s|
|1M   |  10M|   1000|   1100| 10.12s| 10.48s|
|1M   |  10M|   1000|   2000| 12.95s| 13.36s|

These are back to the pretty sweet numbers we saw up above. The first row is basically identical to the first row above (which makes sense: there is just one weight in each case). The other rows, with increasing ranges of weights, never really cause problems; they are at worst the times of the two weight case up above. It turns out there is a good reason for that.

### Diagnosing the problem

Let's look at our picture again, and trace through what happens as we perform multiple rounds of iterative updates to our distances.

In the zeroth round we have only the root, at distance zero.

In the first round, we step across each edge, and produce candidate distances for each of EXAMPLE

In the second round, we step across each edge again, and improve the distances to EXAMPLE.

In the third round, we step across each edge again, and again improve the distances to EXAMPLE.

What you might notice here, or perhaps not because the example is somewhat small, is that we are happily investigating fairly large cost paths, and informing nodes downstream about their newly discovered distances, long before we have any reason to believe that these will be final distances.

Consider what will happen in a graph that has edges with weights either one or one thousand. Starting from our source, we should probably follow just weight one edges for quite a while, probably one thousand-ish steps. At that point, we can afford to follow one weight one thousand edge, and should then return to stepping along weight one edges again.

It is not even remotely helpful to step repeatedly along all of those weight one thousand edges; in fact, it is actively harmful if we propagate that information and must then eventually retract all of it (when distances to nodes eventually improve).

We could plausibly have been better off simply *waiting* to traverse high-weight edges.

### Waiting

There is a slight change we can make to the body of our loop that will delay updates to later rounds of iteration. Unfortunately, we need to drop down to *timely* dataflow, where we can directly manipulate differential dataflow's `(data, time, diff)` triples. We will just pop those open, and advance the round of iteration in `time` to be the distance reported in `data`.

Crazy, right? Probably...

```rust
    dists.join(&edges)
         .map(|(k,l,(d,w))| (d,l+w))
         .concat(&dists)
         // BEGIN NEW
         .inner
         .map(|((d,w),mut t,r)| {
            t.inner = ::std::cmp::max(t.inner, w as u64);
            ((d,w),t,r)
         })
         // END NEW
         .as_collection()
         .reduce(|_, s, t| t.push((*s[0].0, 1)))
```

In fact, this works great. The experimental numbers above that went up to 27 seconds for five weights reduce down to:

|nodes|edges|minimum|maximum|compute|update|
|----:|----:|------:|------:|------:|-----:|
|1M   |  10M|      1|      1|  7.49s| 7.73s|
|1M   |  10M|      1|      2|  8.79s| 9.09s|
|1M   |  10M|      1|      3|  9.83s|10.32s|
|1M   |  10M|      1|      4| 10.72s|11.19s|
|1M   |  10M|      1|      5| 11.48s|11.96s|

Amazing!

And where we went up to one hundred seconds to compute and six seconds to update, we now see only:

|nodes|edges|minimum|maximum|compute| update|
|----:|----:|------:|------:|------:|------:|
|1M   |  10M|      1|      1|  7.36s|  7.60s|
|1M   |  10M|      1|     10| 15.09s| 15.99s|
|1M   |  10M|      1|    100| 34.22s| 36.17s|
|1M   |  10M|      1|   1000|127.02s|132.97s|

Eh. That was *almost* amazing. What new misery has befallen us?

### Waiting faster

Perhaps you recall learning about Dijkstra's algorithm, a sweet single-source shortest path algorithm; it is a great example of when you would learn about a [priority queue](https://en.wikipedia.org/wiki/Priority_queue), a neat data structure that lets you quickly update and extract the minimal element from a set.

We have desperate need of such a data structure here.

Our problem is that with 1,000 distinct weights, we regularly have updates at 1,000 distinct future rounds. Differential dataflow's internal datastructures are not clever enough to behave like priority queues, and in each round will re-scan all of our updates. All that re-scanning, only to process roughly one out of each one thousand.

We can mitigate this somewhat with timely dataflow's `delay` operator, which will bundle together updates at the same time and just consider each time at most once (independent of the number of updates). We need one more line to make this happen, where we trigger the `delay` operator, using for each record the differential dataflow timestamp.

```rust
    dists.join(&edges)
         .map(|(k,l,(d,w))| (d,l+w))
         .concat(&dists)
         .inner
         .map(|((d,w),mut t,r)| {
            t.inner = ::std::cmp::max(t.inner, w as u64);
            ((d,w),t,r)
         })
         // BEGIN NEW
         .delay(|(_,t,_),_| t.clone())
         // END NEW
         .as_collection()
         .reduce(|_, s, t| t.push((*s[0].0, 1)))
```

The result is a touch slower on the single-weight case, but it starts to dramatically improve after that.

|nodes|edges|minimum|maximum|compute| update|
|----:|----:|------:|------:|------:|------:|
|1M   |  10M|      1|      1|  8.17s|  8.39s|
|1M   |  10M|      1|     10| 14.87s| 15.74s|
|1M   |  10M|      1|    100| 25.81s| 27.82s|
|1M   |  10M|      1|   1000| 36.93s| 41.14s|

This is now much less embarassing than it was before. It isn't wonderful yet (don't ask about the COST here), but it is a significant improvement over where we started.

### Other examples

There is another example of programming with time that we've had for quite a while in differential dataflow: prioritized label propagation.

Label propagation is a way to determine the connected components of an undirected graph, in which each node announces a "label" (initially its own name) to all of its neighbors, and then updates its label to be the least value received from its neighbors. The process iterates until all labels are locked in, at which point each node holds the least label within its connected component.

Label propagation is a pretty bad algorithm. One of its particular defects is that it eagerly circulates large labels even though almost all of these labels are going to get clobbered by a smaller label.

Why not start circulating small labels first, and move to large labels only later in the computation? The small labels will move around quickly, and the large labels will arrive only to be clobbered by the small label already held by the node bearing the large label's name.

This results in a fairly significant speed-up, both for the initial computation of labels and for incremental updates to the set of labels (because with less work done, less needs to change).

EVIDENCE

### Conclusions

Most dataflow models don't normally let you specify much about *when* computation happens.
By contrast, *timely* dataflow lets you program with times, delaying data and deferring the computation it will provoke. This allows us to write programs that have finer control over which computations happen first, which allows us to write more efficient programs.

Although I haven't investigated it, my guess is that most iterative graph processors do *not* support this sort of programming with time. Systems that cannot delay processing can be stuck with less efficient execution.